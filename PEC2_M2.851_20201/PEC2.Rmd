---
title: "PEC2_M2.851_20201"
author: "Víctor Morant y Aitor Jara"
date: '`r format(Sys.Date(),"%e de %B, %Y")`'
output: 
  html_document:
    toc: yes
    number_sections: yes
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Descripción del dataset. ¿Por qué es importante y qué pregunta/problema pretende  responder? 

El conjunto de datos del "Titanic" nos parece de especial relevancia, ya que blablabla.... y a su vez pretendemos responder a la pregunta blablabla

# Integración y selección de los datos de interés a analizar. 

Cargamos el conjunto de datos y además modificamos el tipo de algunos de los campos para los cuales creemos que es relevante hacerlo

```{r load_data}
library(readr)

data <- read_csv("train.csv", col_types = cols(Embarked = col_factor(levels = c("S", 
    "Q", "C")), PassengerId = col_integer(), 
    Pclass = col_factor(levels = c("1", "2", 
        "3")), Sex = col_factor(levels = c("male", 
        "female")), Survived = col_factor(levels = c("0", 
        "1"))))

View(data)
```

Visualizamos un resumen de los cambios

```{r}
str(data)
summary(data)
```

# Limpieza de los datos. 
## ¿Los datos contienen ceros o elementos vacíos? ¿Cómo gestionarías cada uno  de estos casos?

Los datos contienen algunos valores nulos que a continuación se muestran númericamente y gráficamente las variables con valores NA o nulos.

```{r}
data_na<-colSums(is.na(data))
print(data_na)
barplot(data_na)
```

Se puede observar claramente que existen 3 variables del conjunto de datos seleccionados que presentan nulos o elementos vacíos, estas son por orden de mayor a menor número de NA: Cabin, Age, Embarked.

Estas 3 variables, como se ha descrito anteriormente son de formato caracter para Cabin, Númerico para Age y de Factor para Embarked.

Uno de los métodos más comunes para gestionar los valores nulos en caso de que el formato sea númerico es por el método de susitución por la mediana. Este método consiste en calcular la mediana de todos los valores de esa variable que no sean nulos y sustituir los nulos por el resultado de la mediana.

Reemplazamos los valores NA de la edad por la mediana

```{r}
df<-data
df$Age[is.na(df$Age)]<-median(data$Age,na.rm=TRUE)
print(colSums(is.na(df)))
```

Como resultado los valores nulos de la variable Age se han sustituido por la mediana calculada.

En el caso de los valores de la variable Embarked observamos que solo existen 3 registros con valores nulos. En este caso, eliminamos los NA de la variable Embarked ya que no son estadísticamente significativos comparados con las 889 observaciones restantes.

```{r}
library(dplyr)
df<-df %>% filter(!is.na(Embarked))
print(colSums(is.na(df)))
```

En el caso de la variable Cabin contiene 3/4 de valores nulos, por lo que no sería prudente imputar todos esos valores ya que nos estaríamos basando en una suposición falsa. Obviaremos este atributo

```{r}
#library(dplyr)
#df2<-data %>% filter(!is.na(Embarked))
df$Cabin <- NULL
print(colSums(is.na(df)))
```

## Identificación y tratamiento de valores extremos. 

Para la visualización de valores extremos, usaremos histogramas y gráficos de caja (box-plots) de las variables de tipo númericas, para intentear identrificar si visualmente podemos observar los valores extremos.

```{r Graphic Anlysis Extreme Values}
par(mfrow=c(1,2))
boxplot(data$Age, main="Age")
hist(data$Age, main="Age")

par(mfrow=c(1,2))
boxplot(data$Fare, main="Fare")
hist(data$Fare, main="Fare")

par(mfrow=c(1,2))
boxplot(data$SibSp, main="SibSp")
hist(data$SibSp, main="SibSp")

par(mfrow=c(1,2))
boxplot(data$Parch, main="Parch")
hist(data$Parch, main="Parch")
```

Se puede observar en los gráficos mostrados anteriormente como en todos los casos podemos observar cierto grado de valores extremos en las variables númericas.

A continuación, realizaremos contenedores nuevos con los valores de "Age", "Fare", "SibSp" y "Parch", deshaciendonos de los outliers identificados anteriormente.

Para realizar esta acción crearemos una función que bla bla (Victor: si podemos explicar un poco que hace la función)

```{r}
library(ggplot2)
outlier_norm <- function(x){
   qntile <- quantile(x, probs=c(.25, .75))
   caps <- quantile(x, probs=c(.05, .95))
   H <- 1.5 * IQR(x, na.rm = T)
   x[x < (qntile[1] - H)] <- caps[1]
   x[x > (qntile[2] + H)] <- caps[2]
   return(x)
}

df$Age=outlier_norm(df$Age)
par(mfrow=c(1,2))
boxplot(df$Age, main="Age")
hist(df$Age, main="Age")

df$Fare=outlier_norm(df$Fare)
par(mfrow=c(1,2))
boxplot(df$Fare, main="Fare")
hist(df$Fare, main="Fare")

df$SibSp=outlier_norm(df$SibSp)
par(mfrow=c(1,2))
boxplot(df$SibSp, main="SibSp")
hist(df$SibSp, main="SibSp")

df$Parch=outlier_norm(df$Parch)
par(mfrow=c(1,2))
boxplot(df$Parch, main="Parch")
hist(df$Parch, main="Parch")

#table(data$Sex)
#table(data$Survived)
#warnings()
```

Podemos observar como los valores extremos han desaparecido en las variables identificadas, por tanto hemos 

```{r}
#table(data$Sex)
#table(data$Survived)
warnings()
```



# Análisis de los datos. 

## Selección de los grupos de datos que se quieren analizar/comparar (planificación  de los análisis a aplicar).

```{r}
male_survived <- data[data$Sex == "male","Survived"]
female_survived <- data[data$Sex == "female","Survived"]
```

Aitor: Para predecir survived/no survived podemos hacer "N" grupos. Por ejemplo:
1- survived ~ sex + class
2- survived ~ sex

Pero yo lo decidiria despues del estudio de correlación (mira mas abajo), para hacer grupos que no tengan relacion entre si, o cuanta menos mejor.

Y luego se haria logistic regression. Para hacer logistic regression con un grupo se haría asi:

```{r}
modelo.logit <- glm(data = df, formula = Survived ~ Sex + Age + Pclass + Embarked, family = "binomial")
summary(modelo.logit)
```

## Comprobación de la normalidad y homogeneidad de la varianza. 

### Comprobación de la normalidad
Aitor: Este es tal cual así

```{r}
par(mfrow = c(1,2))
plot(modelo_multiple)
```

Para la comprobación de la normalidad vamos a comprobamos si la variable se aproxima a un modelo de normalidad en las muestras. 

```{r}
qqnorm(data$Age)
qqline(data$Age)
```

```{r}
boxplot(data$Age, main="Age")
```

Una forma menos subjetiva de explorar la normalidad de un conjunto de datos es por medio de las pruebas de normalidad. Se va a usar un intervalo de confianza estandar del 95%. Las hipótesis para este tipo de pruebas son:

$$
\begin{array}{ll}
H_{0}: La&muestra&proviene&de&una&población&normal.\\
H_{1}: La&muestra&proviene&de&una&población&no&normal.\\
\end{array}
$$
A continuación vamos a relalizar las pruebas de normalidad de shapiro-test, ya que la muestra de población es significativa.

```{r}
shapiro.test(df$Age)
```

En este caso podemos observar que el p-values<0.05, por tanto debemos rechazar la hipotesis nula a favor de la alternativa y afirmar que estos datos no provienen de una población normalmente distribuida. 


### Homogendeidad de la varianza de Age

```{r}
male_survived <- data[data$Sex == "male","Survived"]
female_survived <- data[data$Sex == "female","Survived"]
fligner.test(x = list(male_survived,female_survived))

```



## Aplicación de pruebas estadísticas para comparar los grupos de datos. En función  de los datos y el objetivo del estudio, aplicar pruebas de contraste de hipótesis,  correlaciones, regresiones, etc. Aplicar al menos tres métodos de análisis  diferentes. 

Aitor: Para hacerlo con el resto de atributos hay que pasarlo a numerico, haciendolo como tu (Victor) lo has hecho en el primer paso.

Luego haria logistic regression (como he puesto mas arriba)

Y por ultimo un contraste de hipotesis (miralo en tu pec de estadistica, creo que está hecho ahí)

```{r}
df$Survived <- as.numeric(df$Survived)
df$Sex <- as.numeric(df$Sex)
df$Fare <- as.numeric(df$Fare)
df$Pclass <- as.numeric(df$Pclass)
df$Embarked <- as.numeric(df$Embarked)

require(corrplot)                                                                                                           
corrplot.mixed(corr = cor(df[,c("SibSp", "Parch", "Sex", "Fare", "Pclass", "Embarked", "Survived")],
                          method = "pearson"))
```


# Representación de los resultados a partir de tablas y gráficas.



```{r}
library(ggplot2)
library(dplyr)
```

```{r}
df$Survived <- as.numeric(df$Survived)
df$Sex <- as.numeric(df$Sex)
df$Fare <- as.numeric(df$Fare)
df$Pclass <- as.numeric(df$Pclass)
df$Embarked <- as.numeric(df$Embarked)

require(corrplot)                                                                                                           
corrplot.mixed(corr = cor(df[,c("SibSp", "Parch", "Sex", "Fare", "Pclass", "Embarked", "Survived")],
                          method = "pearson"))
```

A través de este gráfico podemos observar que existe una relación muy alta entre las variables de Supervivencia con Sexo y Suvervivencia con Clase. El resto de relaciones es aparentemente obvio ya que el precio pagadao por el billete va muy relacionado con la clase y por tanto no aporta ninguna información interesante. Por otro lado lo mismo ocurre entre las variables de SibSp y Parch ya que directamente estan muy relacionadas entre ellas y tampoco aportan información imteresante.

```{r}
ggplot(data, aes(x=factor(1), fill=factor(Sex))) + geom_bar(width = 1) + coord_polar("y")
```

En primer lugar podemos ver según el estudio realizado había muchos más hombres que mujeres en el interior del barco. Sin embargo, a partir de un grafico de barras se ve claramente como hubo muchos más supervivientes mujeres que hombres.

```{r}
tbl <- with(data, table(Survived, Sex))
barplot(tbl, beside = TRUE, legend = TRUE)
```

```{r}
ggplot(data, aes(x=factor(1), fill=factor(Pclass))) + geom_bar(width = 1) + coord_polar("y")
```
También observamos que la mayor parte de los tripulantes eran de tercera clase y que de segunda y primera tenian una proporcion similar entre ellos.
 
Pero si intentamos realizar el analisis visual de supervivientes en función de a clase: 


```{r}
tbl <- with(data, table(Survived, Pclass))
barplot(tbl, beside = TRUE, legend = TRUE)
```

Vemos como claramente que la una gran parte de los supervivientes eran de primera clase aunque la proporción es menor que en la tercera.

# Resolución del problema. A partir de los resultados obtenidos, ¿cuáles son las  conclusiones? ¿Los resultados permiten responder al problema?

Como conclusiones del estudio, podemos concluir que si eras mujer y de primera clase, las probabilidades de sobrevivir eran mucho más altas en cualquier otro caso. En cambio, si pertenecías al grupo de tercera clase y eras hombre, las probabilidades de sobrevivir eran bastante escasas.


# Código: Hay que adjuntar el código, preferiblemente en R, con el que se ha realizado la  limpieza, análisis y representación de los datos. Si lo preferís, también podéis trabajar en  Python.  
